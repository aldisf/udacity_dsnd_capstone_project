{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Data Scientist Nanodegree - Starbucks Capstone Challenge\n",
    "\n",
    "This repository houses the analysis on Udacity's Starbucks capstone project.\n",
    "\n",
    "In this analysis, we will analyze the offers, transaction and profile demographics that were a part of Starbucks' marketing campaign (simulated). \n",
    "\n",
    "The goal of this notebook is to identify a way to better make decision on whether someone should be a target of a particular marketing offer. An ideal candidate should both `view` and `complete` the offer once it has been sent. \n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "This data set contains simulated data that mimics customer behavior on the Starbucks rewards mobile app. Once every few days, Starbucks sends out an offer to users of the mobile app. An offer can be merely an advertisement for a drink or an actual offer such as a discount or BOGO (buy one get one free). Some users might not receive any offer during certain weeks. \n",
    "\n",
    "Not all users receive the same offer, and that is the challenge to solve with this data set.\n",
    "\n",
    "Your task is to combine transaction, demographic and offer data to determine which demographic groups respond best to which offer type. This data set is a simplified version of the real Starbucks app because the underlying simulator only has one product whereas Starbucks actually sells dozens of products.\n",
    "\n",
    "Every offer has a validity period before the offer expires. As an example, a BOGO offer might be valid for only 5 days. You'll see in the data set that informational offers have a validity period even though these ads are merely providing information about a product; for example, if an informational offer has 7 days of validity, you can assume the customer is feeling the influence of the offer for 7 days after receiving the advertisement.\n",
    "\n",
    "You'll be given transactional data showing user purchases made on the app including the timestamp of purchase and the amount of money spent on a purchase. This transactional data also has a record for each offer that a user receives as well as a record for when a user actually views the offer. There are also records for when a user completes an offer. \n",
    "\n",
    "Keep in mind as well that someone using the app might make a purchase through the app without having received an offer or seen an offer.\n",
    "\n",
    "\n",
    "# 2. Data Sets\n",
    "\n",
    "The folder /data contains three files\n",
    "\n",
    "* portfolio.json - containing offer ids and meta data about each offer (duration, type, etc.)\n",
    "* profile.json - demographic data for each customer\n",
    "* transcript.json - records for transactions, offers received, offers viewed, and offers completed\n",
    "\n",
    "Here is the schema and explanation of each variable in the files:\n",
    "\n",
    "**portfolio.json**\n",
    "* id (string) - offer id\n",
    "* offer_type (string) - type of offer ie BOGO, discount, informational\n",
    "* difficulty (int) - minimum required spend to complete an offer\n",
    "* reward (int) - reward given for completing an offer\n",
    "* duration (int) - time for offer to be open, in days\n",
    "* channels (list of strings)\n",
    "\n",
    "**profile.json**\n",
    "* age (int) - age of the customer \n",
    "* became_member_on (int) - date when customer created an app account\n",
    "* gender (str) - gender of the customer (note some entries contain 'O' for other rather than M or F)\n",
    "* id (str) - customer id\n",
    "* income (float) - customer's income\n",
    "\n",
    "**transcript.json**\n",
    "* event (str) - record description (ie transaction, offer received, offer viewed, etc.)\n",
    "* person (str) - customer id\n",
    "* time (int) - time in hours since start of test. The data begins at time t=0\n",
    "* value - (dict of strings) - either an offer id or transaction amount depending on the record\n",
    "\n",
    "\n",
    "# 3. Dependencies\n",
    "\n",
    "You will need the following python packages to run this notebook:\n",
    "\n",
    "- numpy \n",
    "- pandas\n",
    "- sklearn \n",
    "- matplotlib\n",
    "- seaborn\n",
    "\n",
    "\n",
    "# 4. Results and Conclusion\n",
    "\n",
    "1. Whether or not a particular offer will be viewed by the recipient depends far more heavily on the distribution channel that was used. This was concluded when offers disseminated to similar demographic target groups while having different distribution channel turned out to have a wide gap in the view rate. Social media channels are particularly very important, as we are seeing the view rate suffer for offers that were not distributed via social media channel.\n",
    "\n",
    "\n",
    "<img src='imgs/viewed_table.png'>\n",
    "\n",
    "\n",
    "\n",
    "2. Two models are produced in this analysis: \n",
    "    - Simpler, baseline model that only takes into account the target's demographic features (Gender, Income and Age) to produce the probability that the person will complete the particular offer. Threshold were chosen by optimizing for f1-score. At the highest f1-score combination, the model has a 69% precision and 98% recall. \n",
    "    \n",
    "    - A Random Forest classifier leveraging more features including transacted amounts and tenure. The model has an average improvement of around 10% in precision, yet this improvement diminishes at very high recall rates. \n",
    "    \n",
    "    \n",
    "<img src='imgs/pr_lift.png'>\n",
    "    \n",
    "Choosing between these two models will depend on whether the best marketing strategy is best obtained through maximizing recall or whether the perceived cost of sending a wasted offer is deemed as too high so that a higher precision is needed. \n",
    "\n",
    "If maximizing recall is the strategy, the first simpler, baseline model will do just fine, and will have an added benefit of faster training & inference time. However, if higher precision is needed, then Random Forest model is preferred.\n",
    "\n",
    "As both models outputs the probability, a threshold needs to be chosen as well. Again, this threshold depends on the precision/recall trade-off, and can be evaluated better to maximize the dollar gain of the campaign. As such information is not available for this analysis, the threshold is chosen by maximizing the f1-score instead.\n",
    "\n",
    "\n",
    "\n",
    "# 5. Acknowledgments\n",
    "1. Udacity - for designing the course and the project\n",
    "2. Starbucks - for providing the dataset and project opportunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
